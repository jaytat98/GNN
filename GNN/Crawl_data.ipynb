{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e87fd416",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cab251a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['AYX']: Exception('%ticker%: No timezone found, symbol may be delisted')\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['SPLK']: Exception('%ticker%: No timezone found, symbol may be delisted')\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['XLNX']: Exception('%ticker%: No timezone found, symbol may be delisted')\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['ATVI']: Exception('%ticker%: No timezone found, symbol may be delisted')\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['ZNGA']: Exception('%ticker%: No timezone found, symbol may be delisted')\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['SGMS']: Exception('%ticker%: No timezone found, symbol may be delisted')\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been fetched and saved to 'stock_prices.csv'.\n"
     ]
    }
   ],
   "source": [
    "stocks = {\n",
    "    \"AI\": [\"NVDA\"],\n",
    "    \"Technology\": [\"MSFT\", \"GOOGL\", \"AMZN\", \"AAPL\", \"ADBE\", \"CRM\", \"CSCO\", \"INTC\", \"HPQ\", \"NFLX\", \"QCOM\", \"TXN\", \"NOW\", \"IBM\", \"AYX\", \"AI\", \"SPLK\", \"VERI\", \"PLTR\", \"ORCL\"],\n",
    "    \"Semiconductor\": [\"AMD\", \"MU\", \"NXPI\", \"ADI\", \"AMAT\", \"LRCX\", \"MRVL\", \"AVGO\", \"ON\", \"XLNX\"],\n",
    "    \"Biotechnology\": [\"ILMN\", \"REGN\", \"VRTX\", \"AMGN\", \"BIIB\", \"GILD\", \"MRNA\", \"CRSP\", \"NVAX\", \"BMRN\"],\n",
    "    \"Banking\": [\"JPM\", \"BAC\", \"WFC\", \"C\", \"GS\", \"MS\", \"USB\", \"PNC\", \"TFC\", \"COF\"],\n",
    "    \"Gaming\": [\"EA\", \"ATVI\", \"TTWO\", \"ZNGA\", \"RBLX\", \"U\", \"NTES\", \"SGMS\", \"PLTK\", \"CCOEY\"],\n",
    "    \"Energy and Electric\": [\"VST\", \"NRG\", \"SO\", \"AEP\", \"EIX\", \"DUK\", \"NEE\", \"EXC\", \"ETR\", \"ED\"],\n",
    "    \"Manufacturing\": [\"BA\", \"CAT\", \"MMM\", \"HON\", \"ITW\", \"PH\", \"SWK\", \"CMI\", \"EMR\", \"DE\"]\n",
    "}\n",
    "\n",
    "# Create an empty DataFrame to store the data\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "# Define the date range\n",
    "start_date = \"2018-01-01\"\n",
    "end_date = \"2024-06-01\"\n",
    "\n",
    "# Fetch data for each stock\n",
    "for sector, tickers in stocks.items():\n",
    "    for ticker in tickers:\n",
    "        # Fetch the historical data\n",
    "        data = yf.download(ticker, start=start_date, end=end_date)\n",
    "        \n",
    "        # Add a column for the ticker symbol\n",
    "        data['Ticker'] = ticker\n",
    "        \n",
    "        # Add a column for the sector\n",
    "        data['Sector'] = sector\n",
    "        \n",
    "        # Append the data to the all_data DataFrame\n",
    "        all_data = pd.concat([all_data, data])\n",
    "\n",
    "# Save the data to a CSV file\n",
    "all_data.to_csv('historical_prices.csv')\n",
    "\n",
    "print(\"Data has been fetched and saved to 'stock_prices.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccb0d342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Financial data has been successfully fetched, calculated, merged, and saved.\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# Define the stock tickers for each sector, ensuring no duplicates and only including those listed before 2018\n",
    "sectors = {\n",
    "    \"AI\": [\"NVDA\"],\n",
    "    \"Technology\": [\"MSFT\", \"GOOGL\", \"AMZN\", \"AAPL\", \"ADBE\", \"CRM\", \"CSCO\", \"INTC\", \"HPQ\", \"NFLX\", \"QCOM\", \"TXN\", \"NOW\", \"IBM\", \"VERI\", \"PLTR\", \"ORCL\"],\n",
    "    \"Semiconductor\": [\"AMD\", \"MU\", \"NXPI\", \"ADI\", \"AMAT\", \"LRCX\", \"MRVL\", \"AVGO\", \"ON\"],\n",
    "    \"Biotechnology\": [\"ILMN\", \"REGN\", \"VRTX\", \"AMGN\", \"BIIB\", \"GILD\", \"MRNA\", \"CRSP\", \"NVAX\", \"BMRN\"],\n",
    "    \"Banking\": [\"JPM\", \"BAC\", \"WFC\", \"C\", \"GS\", \"MS\", \"USB\", \"PNC\", \"TFC\", \"COF\"],\n",
    "    \"Gaming\": [\"EA\", \"TTWO\", \"RBLX\", \"U\", \"NTES\", \"PLTK\", \"CCOEY\"],\n",
    "    \"Energy and Electric\": [\"VST\", \"NRG\", \"SO\", \"AEP\", \"EIX\", \"DUK\", \"NEE\", \"EXC\", \"ETR\", \"ED\"],\n",
    "    \"Manufacturing\": [\"BA\", \"CAT\", \"MMM\", \"HON\", \"ITW\", \"PH\", \"SWK\", \"CMI\", \"EMR\", \"DE\"]\n",
    "}\n",
    "\n",
    "# Define the start and end date for the data\n",
    "start_date = \"2018-01-01\"\n",
    "end_date = \"2024-06-30\"\n",
    "\n",
    "# Create a dictionary to store the financial data\n",
    "financial_data = {}\n",
    "\n",
    "# Fetch the financial data\n",
    "for sector, tickers in sectors.items():\n",
    "    sector_data = {}\n",
    "    for ticker in tickers:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        # Get historical market data\n",
    "        hist = stock.history(start=start_date, end=end_date)\n",
    "        # Get additional financial metrics\n",
    "        stock_info = stock.info\n",
    "        \n",
    "        # Calculate P/E Ratio\n",
    "        try:\n",
    "            eps = stock_info['trailingEps']\n",
    "            hist['P/E'] = hist['Close'] / eps\n",
    "        except KeyError:\n",
    "            hist['P/E'] = None\n",
    "        \n",
    "        # Calculate P/B Ratio\n",
    "        try:\n",
    "            book_value_per_share = stock_info['bookValue']\n",
    "            hist['P/B'] = hist['Close'] / book_value_per_share\n",
    "        except KeyError:\n",
    "            hist['P/B'] = None\n",
    "        \n",
    "        # Add Beta and other info\n",
    "        data['Sector'] = sector\n",
    "        \n",
    "        hist['Beta'] = stock_info.get('beta')\n",
    "        hist['Market Cap'] = stock_info.get('marketCap')\n",
    "        hist['Dividend Yield'] = stock_info.get('dividendYield')\n",
    "        \n",
    "        sector_data[ticker] = hist\n",
    "    financial_data[sector] = sector_data\n",
    "\n",
    "# Combine data into a single DataFrame for each sector and then merge all sectors\n",
    "combined_data = pd.DataFrame()\n",
    "for sector, data in financial_data.items():\n",
    "    sector_df = pd.concat(data.values(), keys=data.keys(), names=[\"Ticker\", \"Date\"])\n",
    "    combined_data = pd.concat([combined_data, sector_df])\n",
    "\n",
    "# Save the combined data to a single CSV file\n",
    "combined_data.to_csv(\"master_data.csv\")\n",
    "\n",
    "print(\"Financial data has been successfully fetched, calculated, merged, and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87bb4056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticker                           AAPL        ADBE         ADI        AEP  \\\n",
      "Date                                                                       \n",
      "2018-01-02 00:00:00-05:00   40.615891  177.699997   79.776619  57.495667   \n",
      "2018-01-03 00:00:00-05:00   40.608810  181.039993   80.766327  57.011295   \n",
      "2018-01-04 00:00:00-05:00   40.797451  183.220001   80.677956  56.336388   \n",
      "2018-01-05 00:00:00-05:00   41.261929  185.339996   81.004890  56.217274   \n",
      "2018-01-08 00:00:00-05:00   41.108673  185.039993   81.146301  56.709564   \n",
      "...                               ...         ...         ...        ...   \n",
      "2024-05-24 00:00:00-04:00  189.979996  475.429993  231.588806  88.970001   \n",
      "2024-05-28 00:00:00-04:00  189.990005  478.429993  232.515137  88.620003   \n",
      "2024-05-29 00:00:00-04:00  190.289993  477.600006  227.246078  87.470001   \n",
      "2024-05-30 00:00:00-04:00  191.289993  445.869995  229.088760  88.160004   \n",
      "2024-05-31 00:00:00-04:00  192.250000  444.760010  233.560974  90.250000   \n",
      "\n",
      "Ticker                            AI        AMAT         AMD        AMGN  \\\n",
      "Date                                                                       \n",
      "2018-01-02 00:00:00-05:00        NaN   49.128437   10.980000  145.396439   \n",
      "2018-01-03 00:00:00-05:00        NaN   49.999111   11.550000  148.140076   \n",
      "2018-01-04 00:00:00-05:00        NaN   50.286255   12.120000  147.515793   \n",
      "2018-01-05 00:00:00-05:00        NaN   50.573402   11.880000  148.394730   \n",
      "2018-01-08 00:00:00-05:00        NaN   51.796047   12.280000  148.353683   \n",
      "...                              ...         ...         ...         ...   \n",
      "2024-05-24 00:00:00-04:00  24.040001  220.889999  166.360001  305.839996   \n",
      "2024-05-28 00:00:00-04:00  24.100000  221.320007  171.610001  300.190002   \n",
      "2024-05-29 00:00:00-04:00  23.920000  219.050003  165.139999  296.369995   \n",
      "2024-05-30 00:00:00-04:00  28.570000  216.539993  166.750000  301.000000   \n",
      "2024-05-31 00:00:00-04:00  29.570000  215.080002  166.899994  305.850006   \n",
      "\n",
      "Ticker                           AMZN         AVGO  ...         SWK  \\\n",
      "Date                                                ...               \n",
      "2018-01-02 00:00:00-05:00   59.450500   215.173996  ...  143.816574   \n",
      "2018-01-03 00:00:00-05:00   60.209999   217.527054  ...  144.345734   \n",
      "2018-01-04 00:00:00-05:00   60.479500   217.599655  ...  144.909027   \n",
      "2018-01-05 00:00:00-05:00   61.457001   218.889023  ...  145.583282   \n",
      "2018-01-08 00:00:00-05:00   62.343498   219.412811  ...  147.358444   \n",
      "...                               ...          ...  ...         ...   \n",
      "2024-05-24 00:00:00-04:00  180.750000  1407.839966  ...   85.328003   \n",
      "2024-05-28 00:00:00-04:00  182.149994  1412.449951  ...   84.129272   \n",
      "2024-05-29 00:00:00-04:00  182.020004  1390.670044  ...   82.167709   \n",
      "2024-05-30 00:00:00-04:00  179.320007  1364.079956  ...   84.555267   \n",
      "2024-05-31 00:00:00-04:00  176.440002  1328.550049  ...   86.358322   \n",
      "\n",
      "Ticker                           TFC        TTWO         TXN          U  \\\n",
      "Date                                                                      \n",
      "2018-01-02 00:00:00-05:00  38.124893  112.879997   88.236954        NaN   \n",
      "2018-01-03 00:00:00-05:00  38.537300  113.879997   90.627403        NaN   \n",
      "2018-01-04 00:00:00-05:00  39.003159  114.019997   90.510384        NaN   \n",
      "2018-01-05 00:00:00-05:00  39.125362  116.910004   91.204109        NaN   \n",
      "2018-01-08 00:00:00-05:00  39.331570  117.370003   91.638756        NaN   \n",
      "...                              ...         ...         ...        ...   \n",
      "2024-05-24 00:00:00-04:00  38.400002  154.600006  199.179993  19.400000   \n",
      "2024-05-28 00:00:00-04:00  37.750000  156.789993  199.600006  19.080000   \n",
      "2024-05-29 00:00:00-04:00  37.459999  159.679993  194.910004  18.750000   \n",
      "2024-05-30 00:00:00-04:00  37.119999  159.779999  195.679993  18.219999   \n",
      "2024-05-31 00:00:00-04:00  37.750000  160.360001  195.009995  18.270000   \n",
      "\n",
      "Ticker                           USB       VERI        VRTX         VST  \\\n",
      "Date                                                                      \n",
      "2018-01-02 00:00:00-05:00  42.577732  23.219999  152.910004   15.905827   \n",
      "2018-01-03 00:00:00-05:00  42.995388  23.730000  152.009995   15.948997   \n",
      "2018-01-04 00:00:00-05:00  43.326363  23.660000  153.070007   15.966269   \n",
      "2018-01-05 00:00:00-05:00  43.594292  23.410000  155.690002   16.130337   \n",
      "2018-01-08 00:00:00-05:00  43.657337  24.010000  156.889999   16.147608   \n",
      "...                              ...        ...         ...         ...   \n",
      "2024-05-24 00:00:00-04:00  40.529999   3.070000  456.950012  101.835152   \n",
      "2024-05-28 00:00:00-04:00  39.770000   2.980000  446.880005  105.924515   \n",
      "2024-05-29 00:00:00-04:00  39.040001   2.920000  441.130005  103.351212   \n",
      "2024-05-30 00:00:00-04:00  39.380001   2.970000  443.049988  105.096672   \n",
      "2024-05-31 00:00:00-04:00  40.549999   2.950000  455.339996   98.822990   \n",
      "\n",
      "Ticker                           WFC  \n",
      "Date                                  \n",
      "2018-01-02 00:00:00-05:00  50.626549  \n",
      "2018-01-03 00:00:00-05:00  51.016048  \n",
      "2018-01-04 00:00:00-05:00  51.654160  \n",
      "2018-01-05 00:00:00-05:00  52.002224  \n",
      "2018-01-08 00:00:00-05:00  51.413837  \n",
      "...                              ...  \n",
      "2024-05-24 00:00:00-04:00  60.209999  \n",
      "2024-05-28 00:00:00-04:00  59.480000  \n",
      "2024-05-29 00:00:00-04:00  58.750000  \n",
      "2024-05-30 00:00:00-04:00  59.209999  \n",
      "2024-05-31 00:00:00-04:00  59.919998  \n",
      "\n",
      "[1614 rows x 75 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the combined financial data from the CSV file\n",
    "csv_file_path = 'combined_financial_data.csv'  # Replace with the actual path to your CSV file\n",
    "data = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Pivot the data to create a new DataFrame where each stock's 'Close' price is a column\n",
    "close_prices = data.pivot_table(index='Date', columns='Ticker', values='Close')\n",
    "\n",
    "# Save the pivoted DataFrame to a new CSV file\n",
    "close_prices.to_csv('stock_prices.csv')\n",
    "\n",
    "# Display the DataFrame\n",
    "print(close_prices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8bb3472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticker                           AAPL        ADBE         ADI        AEP  \\\n",
      "Date                                                                       \n",
      "2018-01-02 00:00:00-05:00   40.615887  177.699997   79.776611  57.495651   \n",
      "2018-01-03 00:00:00-05:00   40.608814  181.039993   80.766312  57.011318   \n",
      "2018-01-04 00:00:00-05:00   40.797443  183.220001   80.677956  56.336361   \n",
      "2018-01-05 00:00:00-05:00   41.261929  185.339996   81.004906  56.217274   \n",
      "2018-01-08 00:00:00-05:00   41.108677  185.039993   81.146317  56.709568   \n",
      "...                               ...         ...         ...        ...   \n",
      "2024-06-17 00:00:00-04:00  216.669998  518.739990  232.389999  87.750000   \n",
      "2024-06-18 00:00:00-04:00  214.289993  522.250000  235.380005  87.550003   \n",
      "2024-06-20 00:00:00-04:00  209.679993  522.950012  229.509995  87.879997   \n",
      "2024-06-21 00:00:00-04:00  207.490005  533.440002  231.050003  87.050003   \n",
      "2024-06-24 00:00:00-04:00  210.875000  527.265015  230.039993  87.900002   \n",
      "\n",
      "Ticker                           AMAT         AMD        AMGN        AMZN  \\\n",
      "Date                                                                        \n",
      "2018-01-02 00:00:00-05:00   49.128437   10.980000  145.396423   59.450500   \n",
      "2018-01-03 00:00:00-05:00   49.999115   11.550000  148.140076   60.209999   \n",
      "2018-01-04 00:00:00-05:00   50.286255   12.120000  147.515778   60.479500   \n",
      "2018-01-05 00:00:00-05:00   50.573399   11.880000  148.394745   61.457001   \n",
      "2018-01-08 00:00:00-05:00   51.796047   12.280000  148.353653   62.343498   \n",
      "...                               ...         ...         ...         ...   \n",
      "2024-06-17 00:00:00-04:00  242.860001  158.399994  303.279999  184.059998   \n",
      "2024-06-18 00:00:00-04:00  247.830002  154.630005  305.989990  182.809998   \n",
      "2024-06-20 00:00:00-04:00  239.990005  161.779999  309.890015  186.100006   \n",
      "2024-06-21 00:00:00-04:00  235.410004  161.229996  308.160004  189.080002   \n",
      "2024-06-24 00:00:00-04:00  232.145004  162.764999  315.375000  187.799896   \n",
      "\n",
      "Ticker                            AVGO          BA  ...         SWK  \\\n",
      "Date                                                ...               \n",
      "2018-01-02 00:00:00-05:00   215.173965  282.886414  ...  143.816574   \n",
      "2018-01-03 00:00:00-05:00   217.527115  283.801270  ...  144.345779   \n",
      "2018-01-04 00:00:00-05:00   217.599640  282.724426  ...  144.909012   \n",
      "2018-01-05 00:00:00-05:00   218.888977  294.322357  ...  145.583252   \n",
      "2018-01-08 00:00:00-05:00   219.412796  295.570740  ...  147.358459   \n",
      "...                                ...         ...  ...         ...   \n",
      "2024-06-17 00:00:00-04:00  1828.869995  178.389999  ...   84.360001   \n",
      "2024-06-18 00:00:00-04:00  1802.520020  174.990005  ...   84.129997   \n",
      "2024-06-20 00:00:00-04:00  1734.560059  176.300003  ...   84.059998   \n",
      "2024-06-21 00:00:00-04:00  1658.630005  176.559998  ...   84.339996   \n",
      "2024-06-24 00:00:00-04:00  1616.500000  180.000000  ...   85.533600   \n",
      "\n",
      "Ticker                           TFC        TTWO         TXN          U  \\\n",
      "Date                                                                      \n",
      "2018-01-02 00:00:00-05:00  38.124886  112.879997   88.236961        NaN   \n",
      "2018-01-03 00:00:00-05:00  38.537292  113.879997   90.627396        NaN   \n",
      "2018-01-04 00:00:00-05:00  39.003166  114.019997   90.510384        NaN   \n",
      "2018-01-05 00:00:00-05:00  39.125362  116.910004   91.204132        NaN   \n",
      "2018-01-08 00:00:00-05:00  39.331566  117.370003   91.638741        NaN   \n",
      "...                              ...         ...         ...        ...   \n",
      "2024-06-17 00:00:00-04:00  35.799999  157.399994  194.899994  16.459999   \n",
      "2024-06-18 00:00:00-04:00  36.570000  155.369995  196.250000  16.080000   \n",
      "2024-06-20 00:00:00-04:00  36.630001  154.979996  192.759995  15.530000   \n",
      "2024-06-21 00:00:00-04:00  36.790001  158.220001  195.529999  15.970000   \n",
      "2024-06-24 00:00:00-04:00  37.415001  159.259995  194.524994  16.472500   \n",
      "\n",
      "Ticker                           USB       VERI        VRTX        VST  \\\n",
      "Date                                                                     \n",
      "2018-01-02 00:00:00-05:00  42.577721  23.219999  152.910004  15.905823   \n",
      "2018-01-03 00:00:00-05:00  42.995388  23.730000  152.009995  15.948996   \n",
      "2018-01-04 00:00:00-05:00  43.326359  23.660000  153.070007  15.966275   \n",
      "2018-01-05 00:00:00-05:00  43.594292  23.410000  155.690002  16.130335   \n",
      "2018-01-08 00:00:00-05:00  43.657341  24.010000  156.889999  16.147608   \n",
      "...                              ...        ...         ...        ...   \n",
      "2024-06-17 00:00:00-04:00  39.090000   2.545000  473.690002  83.821999   \n",
      "2024-06-18 00:00:00-04:00  39.290001   2.510000  467.279999  87.580002   \n",
      "2024-06-20 00:00:00-04:00  39.279999   2.500000  471.380005  88.190002   \n",
      "2024-06-21 00:00:00-04:00  39.700001   2.400000  468.709991  86.860001   \n",
      "2024-06-24 00:00:00-04:00  40.500000   2.304000  475.334503  87.930000   \n",
      "\n",
      "Ticker                           WFC  \n",
      "Date                                  \n",
      "2018-01-02 00:00:00-05:00  50.626553  \n",
      "2018-01-03 00:00:00-05:00  51.016052  \n",
      "2018-01-04 00:00:00-05:00  51.654163  \n",
      "2018-01-05 00:00:00-05:00  52.002220  \n",
      "2018-01-08 00:00:00-05:00  51.413845  \n",
      "...                              ...  \n",
      "2024-06-17 00:00:00-04:00  58.240002  \n",
      "2024-06-18 00:00:00-04:00  59.049999  \n",
      "2024-06-20 00:00:00-04:00  58.959999  \n",
      "2024-06-21 00:00:00-04:00  58.099998  \n",
      "2024-06-24 00:00:00-04:00  59.125000  \n",
      "\n",
      "[1629 rows x 74 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the combined financial data from the CSV file\n",
    "csv_file_path = 'master_data.csv'  # Replace with the actual path to your CSV file\n",
    "data = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Pivot the data to create a new DataFrame where each stock's 'Close' price is a column\n",
    "close_prices = data.pivot_table(index='Date', columns='Ticker', values='Close')\n",
    "\n",
    "# Save the pivoted DataFrame to a new CSV file\n",
    "close_prices.to_csv('stock_prices_01.csv')\n",
    "\n",
    "# Display the DataFrame\n",
    "print(close_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecdbbb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPS data has been saved to quarterly_eps_data.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Your Financial Modeling Prep API key\n",
    "api_key = 'GDzt47ia5m8Z7ukO16SB6jARHviRJbcP'\n",
    "\n",
    "# List of stock tickers\n",
    "tickers = [\n",
    "    \"NVDA\", \"MSFT\", \"GOOGL\", \"AMZN\", \"AAPL\", \"ADBE\", \"CRM\", \"CSCO\", \"INTC\", \"HPQ\", \n",
    "    \"NFLX\", \"QCOM\", \"TXN\", \"NOW\", \"IBM\", \"VERI\", \"ORCL\", \"AMD\", \"MU\", \"NXPI\", \"ADI\", \n",
    "    \"AMAT\", \"LRCX\", \"MRVL\", \"AVGO\", \"ON\", \"ILMN\", \"REGN\", \"VRTX\", \"AMGN\", \"BIIB\", \n",
    "    \"GILD\", \"MRNA\", \"CRSP\", \"NVAX\", \"BMRN\", \"JPM\", \"BAC\", \"WFC\", \"C\", \"GS\", \"MS\", \n",
    "    \"USB\", \"PNC\", \"TFC\", \"COF\", \"EA\", \"TTWO\", \"NTES\", \"CCOEY\", \"VST\", \"NRG\", \"SO\", \n",
    "    \"AEP\", \"EIX\", \"DUK\", \"NEE\", \"EXC\", \"ETR\", \"ED\", \"BA\", \"CAT\", \"MMM\", \"HON\", \"ITW\", \n",
    "    \"PH\", \"SWK\", \"CMI\", \"EMR\", \"DE\"\n",
    "]\n",
    "\n",
    "# Function to get quarterly EPS data for a given ticker\n",
    "def get_eps_data(ticker):\n",
    "    url = f'https://financialmodelingprep.com/api/v3/financials/income-statement/{ticker}?apikey={api_key}'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    if 'financials' in data:\n",
    "        df = pd.DataFrame(data['financials'])\n",
    "        df = df[['date', 'EPS']]\n",
    "        df['Ticker'] = ticker\n",
    "        return df\n",
    "    else:\n",
    "        print(f\"No EPS data for {ticker}\")\n",
    "        return None\n",
    "\n",
    "# Get EPS data for all tickers\n",
    "eps_data = []\n",
    "for ticker in tickers:\n",
    "    data = get_eps_data(ticker)\n",
    "    if data is not None:\n",
    "        eps_data.append(data)\n",
    "\n",
    "# Combine all EPS data into a single DataFrame\n",
    "if eps_data:\n",
    "    eps_df = pd.concat(eps_data)\n",
    "    eps_df.reset_index(inplace=True)\n",
    "\n",
    "    # Save the data to a CSV file\n",
    "    eps_df.to_csv('FMP_quarterly_eps_data.csv', index=False)\n",
    "    print(\"EPS data has been saved to quarterly_eps_data.csv\")\n",
    "else:\n",
    "    print(\"No EPS data available for the provided tickers.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "537f6280",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  70 of 70 completed\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'date'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 94\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m combined_data\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Tính toán P/E và P/B Ratios\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m ratios_data \u001b[38;5;241m=\u001b[39m calculate_ratios(stock_data, eps_df, book_value_df)\n\u001b[0;32m     96\u001b[0m \u001b[38;5;66;03m# Lưu dữ liệu Ratios vào file CSV\u001b[39;00m\n\u001b[0;32m     97\u001b[0m ratios_data\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mratios_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[22], line 77\u001b[0m, in \u001b[0;36mcalculate_ratios\u001b[1;34m(stock_data, eps_df, book_value_df)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_ratios\u001b[39m(stock_data, eps_df, book_value_df):\n\u001b[0;32m     76\u001b[0m     eps_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(eps_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 77\u001b[0m     book_value_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(book_value_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     78\u001b[0m     stock_data \u001b[38;5;241m=\u001b[39m stock_data\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m     79\u001b[0m     stock_data \u001b[38;5;241m=\u001b[39m stock_data\u001b[38;5;241m.\u001b[39mmelt(id_vars\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m], var_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTicker\u001b[39m\u001b[38;5;124m'\u001b[39m, value_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClose\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'date'"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Your Financial Modeling Prep API key\n",
    "api_key = 'GDzt47ia5m8Z7ukO16SB6jARHviRJbcP'\n",
    "\n",
    "# List of stock tickers\n",
    "tickers = [\n",
    "    \"NVDA\", \"MSFT\", \"GOOGL\", \"AMZN\", \"AAPL\", \"ADBE\", \"CRM\", \"CSCO\", \"INTC\", \"HPQ\", \n",
    "    \"NFLX\", \"QCOM\", \"TXN\", \"NOW\", \"IBM\", \"VERI\", \"ORCL\", \"AMD\", \"MU\", \"NXPI\", \"ADI\", \n",
    "    \"AMAT\", \"LRCX\", \"MRVL\", \"AVGO\", \"ON\", \"ILMN\", \"REGN\", \"VRTX\", \"AMGN\", \"BIIB\", \n",
    "    \"GILD\", \"MRNA\", \"CRSP\", \"NVAX\", \"BMRN\", \"JPM\", \"BAC\", \"WFC\", \"C\", \"GS\", \"MS\", \n",
    "    \"USB\", \"PNC\", \"TFC\", \"COF\", \"EA\", \"TTWO\", \"NTES\", \"CCOEY\", \"VST\", \"NRG\", \"SO\", \n",
    "    \"AEP\", \"EIX\", \"DUK\", \"NEE\", \"EXC\", \"ETR\", \"ED\", \"BA\", \"CAT\", \"MMM\", \"HON\", \"ITW\", \n",
    "    \"PH\", \"SWK\", \"CMI\", \"EMR\", \"DE\"\n",
    "]\n",
    "\n",
    "# Function to get quarterly EPS data for a given ticker\n",
    "def get_eps_data(ticker):\n",
    "    url = f'https://financialmodelingprep.com/api/v3/income-statement/{ticker}?apikey={api_key}&limit=120'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    \n",
    "    if isinstance(data, list):\n",
    "        df = pd.DataFrame(data)\n",
    "        df = df[['date', 'eps']]\n",
    "        df['Ticker'] = ticker\n",
    "        return df\n",
    "    else:\n",
    "        print(f\"No EPS data for {ticker}\")\n",
    "        return None\n",
    "\n",
    "# Function to get book value per share data from Yahoo Finance\n",
    "def get_book_value_yahoo(ticker):\n",
    "    stock = yf.Ticker(ticker)\n",
    "    book_value_per_share = stock.info.get('bookValue')\n",
    "    return book_value_per_share\n",
    "\n",
    "# Get EPS data for all tickers\n",
    "eps_data = []\n",
    "book_value_data = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    eps = get_eps_data(ticker)\n",
    "    if eps is not None:\n",
    "        eps_data.append(eps)\n",
    "    \n",
    "    book_value = get_book_value_yahoo(ticker)\n",
    "    if book_value is not None:\n",
    "        book_value_data.append({'Ticker': ticker, 'bookValuePerShare': book_value})\n",
    "\n",
    "# Combine all EPS data into a single DataFrame\n",
    "if eps_data:\n",
    "    eps_df = pd.concat(eps_data)\n",
    "    eps_df.reset_index(inplace=True)\n",
    "    eps_df.to_csv('quarterly_eps_data.csv', index=False)\n",
    "else:\n",
    "    print(\"No EPS data available for the provided tickers.\")\n",
    "\n",
    "# Combine all book value data into a single DataFrame\n",
    "if book_value_data:\n",
    "    book_value_df = pd.DataFrame(book_value_data)\n",
    "    book_value_df.to_csv('book_value_data.csv', index=False)\n",
    "else:\n",
    "    print(\"No book value data available for the provided tickers.\")\n",
    "\n",
    "# Lấy dữ liệu giá cổ phiếu từ Yahoo Finance\n",
    "stock_data = yf.download(tickers, start='2018-01-01', end='2024-01-01')\n",
    "\n",
    "# Chỉ lấy giá đóng cửa\n",
    "stock_data = stock_data['Close']\n",
    "\n",
    "# Tính toán P/E và P/B Ratios cho mỗi ngày\n",
    "def calculate_ratios(stock_data, eps_df, book_value_df):\n",
    "    eps_df['date'] = pd.to_datetime(eps_df['date'])\n",
    "    book_value_df['date'] = pd.to_datetime(book_value_df['date'])\n",
    "    stock_data = stock_data.reset_index()\n",
    "    stock_data = stock_data.melt(id_vars=['Date'], var_name='Ticker', value_name='Close')\n",
    "\n",
    "    # Kết hợp dữ liệu giá đóng cửa với dữ liệu EPS và giá trị sổ sách\n",
    "    combined_data = pd.merge(stock_data, eps_df, left_on=['Date', 'Ticker'], right_on=['date', 'Ticker'], how='left')\n",
    "    combined_data = pd.merge(combined_data, book_value_df, on='Ticker', how='left')\n",
    "\n",
    "    # Tính P/E Ratio\n",
    "    combined_data['P/E'] = combined_data['Close'] / combined_data['eps']\n",
    "\n",
    "    # Tính P/B Ratio\n",
    "    combined_data['P/B'] = combined_data['Close'] / combined_data['bookValuePerShare']\n",
    "\n",
    "    return combined_data\n",
    "\n",
    "# Tính toán P/E và P/B Ratios\n",
    "ratios_data = calculate_ratios(stock_data, eps_df, book_value_df)\n",
    "\n",
    "# Lưu dữ liệu Ratios vào file CSV\n",
    "ratios_data.to_csv('ratios_data.csv', index=False)\n",
    "print(\"Ratios data has been saved to ratios_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b87a80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
